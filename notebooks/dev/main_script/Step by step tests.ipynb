{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy import stats\n",
    "from shutil import copy\n",
    "import pandas as pd\n",
    "\n",
    "from config import CONFIG_INI\n",
    "from mpfit import mpfit\n",
    "from limb_darkening import limb_dark_fit\n",
    "import hstmarg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data setup\n",
    "localDir = CONFIG_INI.get('data_paths', 'local_path')\n",
    "outDir = os.path.join(localDir, CONFIG_INI.get('data_paths', 'output_path'))\n",
    "curr_model = CONFIG_INI.get('data_paths', 'current_model')\n",
    "dataDir = os.path.join(localDir, os.path.join(localDir, CONFIG_INI.get('data_paths', 'data_path')), curr_model)\n",
    "\n",
    "# READ in the txt file for the lightcurve data\n",
    "x, y, err, sh = np.loadtxt(os.path.join(dataDir, 'W17_white_lightcurve_test_data.txt'), skiprows=7, unpack=True)\n",
    "wavelength = np.loadtxt(os.path.join(dataDir, 'W17_wavelength_test_data.txt'), skiprows=3)\n",
    "\n",
    "# Limb darkening parameters - user input\n",
    "ld_model = CONFIG_INI.get('limb_darkening', 'ld_model')\n",
    "FeH = CONFIG_INI.getfloat('limb_darkening', 'metallicity')\n",
    "Teff = CONFIG_INI.getfloat('limb_darkening', 'Teff')\n",
    "logg = CONFIG_INI.getfloat('limb_darkening', 'logg')\n",
    "\n",
    "# More user input\n",
    "grat = CONFIG_INI.get('technical_parameters', 'grating')\n",
    "grid_selection = CONFIG_INI.get('technical_parameters', 'grid_selection')\n",
    "run_name = CONFIG_INI.get('technical_parameters', 'run_name')\n",
    "plotting = CONFIG_INI.get('technical_parameters', 'plotting')\n",
    "\n",
    "# Planet parameters\n",
    "rl = CONFIG_INI.getfloat('planet_parameters', 'rl')             # Rp/R* estimate\n",
    "epoch = CONFIG_INI.getfloat('planet_parameters', 'epoch')       # in MJD\n",
    "inclin = CONFIG_INI.getfloat('planet_parameters', 'inclin')     # this is converted into radians in the subroutine\n",
    "ecc = CONFIG_INI.getfloat('planet_parameters', 'ecc')           # set to zero and not used when circular\n",
    "omega = CONFIG_INI.getfloat('planet_parameters', 'omega')       # set to zero and not used when circular\n",
    "Per = CONFIG_INI.getfloat('planet_parameters', 'Per')           # in days, converted to seconds in subroutine\n",
    "aor = CONFIG_INI.getfloat('planet_parameters', 'aor')           # a/R* converted to system density for the subroutine\n",
    "\n",
    "# Setting constants and preparing inputs for claculations\n",
    "dtosec = CONFIG_INI.getfloat('constants', 'dtosec')     # conversion from days to seconds\n",
    "big_G = CONFIG_INI.getfloat('constants', 'big_G')       # gravitational constant\n",
    "\n",
    "persec = Per * dtosec\n",
    "constant1 = (big_G * persec * persec / np.float32(4. * np.pi * np.pi)) ** (1. / 3.)\n",
    "MsMpR = (aor / constant1) ** 3.\n",
    "\n",
    "# Put data parameters in list\n",
    "data_params = [rl, epoch, inclin, MsMpR, ecc, omega, Per, FeH, Teff, logg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE LIMB DARKENING DIRECTORY, WHICH IS INSIDE THIS PACKAGE\n",
    "limbDir = os.path.join('..', 'Limb-darkening')\n",
    "\n",
    "# READ THE CONSTANTS\n",
    "Gr = CONFIG_INI.getfloat('constants', 'big_G')\n",
    "day_to_sec = CONFIG_INI.getfloat('constants', 'dtosec')\n",
    "HST_period = CONFIG_INI.getfloat('constants', 'HST_period')\n",
    "\n",
    "# We want to keep the raw data as is, so we generate helper arrays that will get changed from model to model\n",
    "img_date = x    # time array\n",
    "img_flux = y    # flux array\n",
    "img_err = err   # error array\n",
    "img_sh = sh     # shift in position array\n",
    "nexposure = len(img_date)   # Total number of exposures in the observation\n",
    "\n",
    "# READ IN THE PLANET STARTING PARAMETERS\n",
    "# data_params = [rl, epoch, inclin, MsMpR, ecc, omega, Per, FeH, Teff, logg]   # Description\n",
    "rl = data_params[0]                             # Rp/R* estimate\n",
    "epoch = data_params[1]                          # center of transit time in MJD\n",
    "inclin = data_params[2] * ((2 * np.pi) / 360)   # inclination, converting it to radians\n",
    "MsMpR = data_params[3]                          # density of the system\n",
    "ecc = data_params[4]                            # eccentricity\n",
    "omega = data_params[5] * ((2 * np.pi) / 360)    # orbital omega, converting it to radians\n",
    "Per = data_params[6] * day_to_sec               # period in seconds\n",
    "constant1 = ((Gr * np.square(Per)) / (4 * np.square(np.pi))) ** (1 / 3)\n",
    "aval = constant1 * (MsMpR) ** (1 / 3)   # NOT-REUSED\n",
    "\n",
    "flux0 = img_flux[0]   # first flux data point\n",
    "T0 = img_date[0]      # first time data point\n",
    "\n",
    "# SET THE STARTING PARAMETERS FOR THE SYSTEMATIC MODELS\n",
    "m_fac = 0.0  # Linear Slope\n",
    "HSTP1 = 0.0  # Correct HST orbital phase\n",
    "HSTP2 = 0.0  # Correct HST orbital phase^2\n",
    "HSTP3 = 0.0  # Correct HST orbital phase^3\n",
    "HSTP4 = 0.0  # Correct HST orbital phase^4\n",
    "xshift1 = 0.0  # X-shift in wavelength\n",
    "xshift2 = 0.0  # X-shift in wavelength^2\n",
    "xshift3 = 0.0  # X-shift in wavelength^3\n",
    "xshift4 = 0.0  # X-shift in wavelength^4\n",
    "\n",
    "# =======================\n",
    "# LIMB DARKENING\n",
    "# NEW: Implement a suggestion for the user to use 3D if his parameters match the options available in the 3D models\n",
    "\n",
    "M_H = data_params[7]    # metallicity\n",
    "Teff = data_params[8]   # effective temperature\n",
    "logg = data_params[9]   # log(g), gravitation\n",
    "\n",
    "uLD, c1, c2, c3, c4, cp1, cp2, cp3, cp4, aLD, bLD = limb_dark_fit(grat, wavelength, M_H, Teff,\n",
    "                                                                       logg, limbDir, ld_model)\n",
    "# =======================\n",
    "\n",
    "# PLACE ALL THE PRIORS IN AN ARRAY\n",
    "# p0 =        [0,    1,     2,      3,     4,    5,    6,    7,  8,  9,  10, 11, 12,  13,    14,    15,    16,    17,     18,      19,      20,      21   ]\n",
    "p0 = np.array([rl, flux0, epoch, inclin, MsMpR, ecc, omega, Per, T0, c1, c2, c3, c4, m_fac, HSTP1, HSTP2, HSTP3, HSTP4, xshift1, xshift2, xshift3, xshift4])\n",
    "\n",
    "# Create an array with the names of the priors\n",
    "p0_names = np.array(['rl', 'flux0', 'epoch', 'inclin', 'MsMpR', 'ecc', 'omega', 'Per', 'T0', 'c1', 'c2', 'c3', 'c4',\n",
    "                     'm_fac', 'HSTP1', 'HSTP2', 'HSTP3', 'HSTP4', 'xshift1', 'xshift2', 'xshift3', 'xshift4'])\n",
    "\n",
    "# Create a dictionary for easier use in calculations\n",
    "p0_dict = {key: val for key, val in zip(p0_names, p0)}\n",
    "\n",
    "# SELECT THE SYSTEMATIC GRID OF MODELS TO USE\n",
    "# 1 in the grid means the parameter is fixed, 0 means it is free\n",
    "grid = hstmarg.wfc3_systematic_model_grid_selection(grid_selection)\n",
    "nsys, nparams = grid.shape   # nsys = number of systematic models, nparams = number of parameters\n",
    "\n",
    "#  SET UP THE ARRAYS\n",
    "\n",
    "# save arrays for the first step through to get the err inflation\n",
    "w_scatter = np.zeros(nsys)\n",
    "w_params = np.zeros((nsys, nparams))   # p0 parameters, but for all the systems in one single array, so that we can acces each one of the individually during the second fit\n",
    "\n",
    "#################################\n",
    "#           FIRST FIT           #\n",
    "#################################\n",
    "\n",
    "print('\\n 1ST FIT \\n')\n",
    "print(\n",
    "    'The first run through the data for each of the WFC3 stochastic models outlined in Table 2 of Wakeford et '\n",
    "    'al. (2016) is now being preformed. Using this fit we will scale the uncertainties you input to incorporate '\n",
    "    'the inherent scatter in the data for each model.')\n",
    "\n",
    "# Loop over all systems (= parameter combinations)\n",
    "for s in range(nsys):\n",
    "    print('\\n################################')\n",
    "    print('SYSTEMATIC MODEL {} of {}'.format(s+1, nsys))\n",
    "    systematics = grid[s, :]\n",
    "    print('Systematics - fixed and free parameters:')\n",
    "    print_dict = {name: fix for name, fix in zip(p0_names, systematics)}\n",
    "    print(print_dict)\n",
    "    print(systematics)\n",
    "    print('  ')\n",
    "\n",
    "    # Displaying img_date in terms of HST PHASE, on an interval between -0.5 and 0.5\n",
    "    HSTphase = (img_date - p0_dict['T0']) / HST_period   # make phase (~time) array start at 0 by subtracting first observation time, convert in units of HST phase by dividing through one HST period\n",
    "    phase2 = np.floor(HSTphase)       # identify where phase is between 0-1, between 1-2, between 2-3 and over 3\n",
    "    HSTphase = HSTphase - phase2      # make phase be in interval from 0 to 1\n",
    "    k = np.where(HSTphase > 0.5)[0]   # figure out where phase is bigger than 0.5\n",
    "    HSTphase[k] -= 1.0                # and where it is bigger than 0.5 indeed, subtract on to get to interval [-0.5, 0.5]\n",
    "\n",
    "    # Displaying img_date in terms of PLANET PHASE, on interval between -0.5 and 0.5\n",
    "    phase = (img_date - p0_dict['epoch']) / (p0_dict['Per'] / day_to_sec)   # make center of transit time by subtracting 'epoch' from img_date, convert in units of planet phase by dividing py planet period, convert to seconds\n",
    "    phase2 = np.floor(phase)          # identify integer intervals of phase (like above)\n",
    "    phase = phase - phase2            # make phase be in interval from 0 to 1\n",
    "    a = np.where(phase > 0.5)[0]      # figure out where phase is bigger than 0.5\n",
    "    phase[a] -= 1.0                   # and where it is bigger than 0.5 indeed, subtract on to get to interval [-0.5, 0.5]\n",
    "\n",
    "    ###############\n",
    "    # MPFIT - ONE #\n",
    "    ###############\n",
    "\n",
    "    # Create two dictionaries in which each parameter in p0 gets some extra parameters assigned, which we then feed\n",
    "    # info mpfit. This dictionary has the sole purpose of preparing the input data for mpfit in such a way that\n",
    "    # it works.\n",
    "    parinfo = []\n",
    "    for i, value in enumerate(p0):\n",
    "        info = {'value': 0., 'fixed': 0, 'limited': [0, 0], 'limits': [0., 0.]}\n",
    "        info['value'] = value\n",
    "        info['fixed'] = systematics[i]\n",
    "        parinfo.append(info)\n",
    "    fa = {'x': img_date, 'y': img_flux, 'err': err, 'sh': sh}\n",
    "\n",
    "    print('\\nSTART MPFIT\\n')\n",
    "    mpfit_result = mpfit(hstmarg.transit_circle, functkw=fa, parinfo=parinfo, quiet=1)\n",
    "    print('\\nTHIS ROUND OF MPFIT IS DONE\\n')\n",
    "\n",
    "    # Count free parameters by figuring out how many zeros we have in the current systematics\n",
    "    nfree = sum([not p['fixed'] for p in parinfo])\n",
    "\n",
    "    # The python mpfit does not populate the covariance matrix correctly so mpfit_result.perror is not correct\n",
    "    # the mpfit_result.covar is filled sequentially by row with the values of only free parameters, this works if\n",
    "    # all parameters are free but not if some are kept fixed.  The code below should work to get the proper error\n",
    "    # values i.e. what should be the diagonals of the covariance.\n",
    "\n",
    "    test_err1 = mpfit_result.perror  # this is how it should be done if it was right\n",
    "\n",
    "    pcerror = np.zeros_like(mpfit_result.perror)\n",
    "    pcerror[:nfree] = np.sqrt(\n",
    "        np.diag(mpfit_result.covar.flatten()[:nfree ** 2].reshape(nfree, nfree)))  # this might work...\n",
    "\n",
    "    bestnorm = mpfit_result.fnorm  # chi squared of resulting fit\n",
    "\n",
    "     # Redefine all of the parameters given the MPFIT output\n",
    "    w_params[s, :] = mpfit_result.params\n",
    "    # Populate parameters with fits results\n",
    "    p0 = w_params[s, :]\n",
    "    # Recreate the dictionary\n",
    "    p0_dict = {key: val for key, val in zip(p0_names, p0)}\n",
    "\n",
    "    # Populate some errors from pcerror array\n",
    "    # pcerror = [rl_err, flux0_err, epoch_err, inclin_err, msmpr_err, ecc_err, omega_err, per_err, T0_err,\n",
    "    #           c1_err, c2_err, c3_err, c4_err, m_err, hst1_err, hst2_err, hst3_err, hst4_err, sh1_err, sh2_err,\n",
    "    #           sh3_err, sh4_err]\n",
    "    rl_err = pcerror[0]\n",
    "\n",
    "    # Recalculate a/R* (actually the constant for it) based on the new MsMpR value which may have been fit in the routine.\n",
    "    constant1 = (Gr * p0_dict['Per'] * p0_dict['Per'] / (4 * np.pi * np.pi)) ** (1 / 3.)\n",
    "\n",
    "    print('\\nTRANSIT DEPTH rl in model {} of {} = {} +/- {}, centered at  {}'.format(s+1, nsys, p0_dict['rl'], rl_err, p0_dict['epoch']))\n",
    "\n",
    "    # OUTPUTS\n",
    "    # Re-Calculate each of the arrays dependent on the output parameters\n",
    "    phase = (img_date - p0_dict['epoch']) / (p0_dict['Per'] / day_to_sec)\n",
    "    phase2 = np.floor(phase)\n",
    "    phase = phase - phase2\n",
    "    a = np.where(phase > 0.5)[0]\n",
    "    phase[a] = phase[a] - 1.0\n",
    "\n",
    "    HSTphase = (img_date - p0_dict['T0']) / HST_period\n",
    "    phase2 = np.floor(HSTphase)\n",
    "    HSTphase = HSTphase - phase2\n",
    "    k = np.where(HSTphase > 0.5)[0]\n",
    "    HSTphase[k] = HSTphase[k] - 1.0\n",
    "\n",
    "    # ...........................................\n",
    "    # TRANSIT MODEL fit to the data\n",
    "    # Calculate the impact parameter based on the eccentricity function\n",
    "    b0 = hstmarg.impact_param(p0_dict['Per'], p0_dict['MsMpR'], phase, p0_dict['inclin'])\n",
    "\n",
    "    mulimb01, mulimbf1 = hstmarg.occultnl(p0_dict['rl'], p0_dict['c1'], p0_dict['c2'], p0_dict['c3'], p0_dict['c4'], b0)\n",
    "\n",
    "    systematic_model = hstmarg.sys_model(phase, HSTphase, sh, p0_dict['m_fac'], p0_dict['HSTP1'], p0_dict['HSTP2'], p0_dict['HSTP3'],\n",
    "                                         p0_dict['HSTP4'], p0_dict['xshift1'], p0_dict['xshift2'],\n",
    "                                         p0_dict['xshift3'], p0_dict['xshift4'])\n",
    "\n",
    "    # Calculate final form of the model fit\n",
    "    w_model = mulimb01 * p0_dict['flux0'] * systematic_model   # see Wakeford et al. 2016, Eq. 1\n",
    "    # Calculate the residuals\n",
    "    w_residuals = (img_flux - w_model) / p0_dict['flux0']\n",
    "    # Calculate more stuff\n",
    "    corrected_data = img_flux / (p0_dict['flux0'] * systematic_model)\n",
    "    w_scatter[s] = np.std(w_residuals)\n",
    "    print('Scatter on the residuals = {}'.format(w_scatter[s]))   # this result is rather different to IDL result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(phase, mulimb01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_err)\n",
    "print(pcerror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#          SECOND FIT          #\n",
    "################################\n",
    "\n",
    "print('..........................................')\n",
    "print('\\n 2ND FIT \\n')\n",
    "print('Each systematic model will now be re-fit with the previously determined parameters serving as the new starting points.')\n",
    "\n",
    "# Initializing arrays for each systematic model, which we will save once we got through all systems with two fits.\n",
    "sys_stats = np.zeros((nsys, 5))                 # stats       # NEW: why 5? (trying to get rid of hard coded things)\n",
    "sys_date = np.zeros((nsys, nexposure))          # img_date\n",
    "sys_phase = np.zeros((nsys, nexposure))         # phase\n",
    "sys_rawflux = np.zeros((nsys, nexposure))       # raw lightcurve flux\n",
    "sys_rawflux_err = np.zeros((nsys, nexposure))   # raw lightcurve flux error\n",
    "sys_flux = np.zeros((nsys, nexposure))          # corrected lightcurve flux\n",
    "sys_flux_err = np.zeros((nsys, nexposure))      # corrected lightcurve flux error\n",
    "sys_residuals = np.zeros((nsys, nexposure))     # residuals\n",
    "sys_model = np.zeros((nsys, 4000))              # smooth model       # NEW: why 4000?\n",
    "sys_model_phase = np.zeros((nsys, 4000))        # smooth phase       # NEW: why 4000?\n",
    "sys_systematic_model = np.zeros((nsys, nexposure))  # systematic model\n",
    "sys_params = np.zeros((nsys, nparams))          # parameters\n",
    "sys_params_err = np.zeros((nsys, nparams))      # parameter errors\n",
    "sys_depth = np.zeros(nsys)                      # depth\n",
    "sys_depth_err = np.zeros(nsys)                  # depth error\n",
    "sys_epoch = np.zeros(nsys)                      # transit time\n",
    "sys_epoch_err = np.zeros(nsys)                  # transit time error\n",
    "sys_evidenceAIC = np.zeros(nsys)                # evidence AIC\n",
    "sys_evidenceBIC = np.zeros(nsys)                # evidence BIC\n",
    "\n",
    "for s in range(nsys):\n",
    "    print('\\n################################')\n",
    "    print('SYSTEMATIC MODEL {} of {}'.format(s+1, nsys))\n",
    "    systematics = grid[s, :]\n",
    "    print_dict = {name: fix for name, fix in zip(p0_names, systematics)}\n",
    "    print(print_dict)\n",
    "    print(systematics)\n",
    "    print('  ')\n",
    "\n",
    "    # Rescale the err array by the standard deviation of the residuals from the fit.\n",
    "    err *= (1.0 - w_scatter[s])   # w_scatter are residuals\n",
    "    # Reset the arrays and start again. This is to ensure that we reached a minimum in the chi-squared space.\n",
    "    p0 = w_params[s, :]   # populate with results from first run FOR THE SYSTEM nsys WE'RE CURRENTLY IN\n",
    "    # Recreate the dictionary\n",
    "    p0_dict = {key: val for key, val in zip(p0_names, p0)}\n",
    "\n",
    "    # HST Phase\n",
    "    HSTphase = np.zeros(nexposure)\n",
    "    HSTphase = (img_date - p0_dict['T0']) / HST_period\n",
    "    phase2 = np.floor(HSTphase)\n",
    "    HSTphase = HSTphase - phase2\n",
    "    k = np.where(HSTphase > 0.5)[0]\n",
    "\n",
    "    if k[0].shape == 0:\n",
    "    #if k[0] != -1:         # in IDL this meant if condition of \"where\" statement is true nowhere\n",
    "        HSTphase[k] = HSTphase[k] - 1.0\n",
    "\n",
    "    phase = np.zeros(nexposure)\n",
    "    for j in range(nexposure):\n",
    "        phase[j] = (img_date[j] - p0_dict['epoch']) / (p0_dict['Per'] / day_to_sec)\n",
    "\n",
    "    phase2 = np.floor(phase)\n",
    "    phase = phase - phase2\n",
    "    a = np.where(phase > 0.5)[0]\n",
    "    if a[0].shape == 0:\n",
    "    #if a[0] != -1:\n",
    "        phase[a] = phase[a] - 1.0\n",
    "\n",
    "    ###############\n",
    "    # MPFIT - TWO #\n",
    "    ###############\n",
    "\n",
    "    parinfo = []\n",
    "\n",
    "    for i, value in enumerate(p0):\n",
    "        info = {'value': 0., 'fixed': 0, 'limited': [0, 0], 'limits': [0., 0.]}\n",
    "        info['value'] = value\n",
    "        info['fixed'] = systematics[i]\n",
    "        parinfo.append(info)\n",
    "\n",
    "    fa = {'x': img_date, 'y': img_flux, 'err': err, 'sh': sh}\n",
    "    mpfit_result = mpfit(hstmarg.transit_circle, functkw=fa, parinfo=parinfo, quiet=1)\n",
    "    nfree = sum([not p['fixed'] for p in parinfo])\n",
    "    # The python mpfit does not populate the covariance matrix correctly so m.perror is not correct\n",
    "    pcerror = mpfit_result.perror  # this is how it should be done if it was right\n",
    "    pcerror = np.zeros_like(mpfit_result.perror)\n",
    "    pcerror[:nfree] = np.sqrt(\n",
    "        np.diag(mpfit_result.covar.flatten()[:nfree ** 2].reshape(nfree, nfree)))  # this might work...\n",
    "\n",
    "    # From mpfit define the DOF, BIC, AIC & CHI\n",
    "    bestnorm = mpfit_result.fnorm  # chi squared of resulting fit\n",
    "    BIC = bestnorm + nfree * np.log(len(img_date))\n",
    "    AIC = bestnorm + nfree\n",
    "    DOF = len(img_date) - sum([p['fixed'] != 1 for p in parinfo])  # nfree\n",
    "    CHI = bestnorm\n",
    "\n",
    "    # EVIDENCE BASED on the AIC and BIC\n",
    "    Mpoint = nfree\n",
    "    Npoint = len(img_date)\n",
    "    sigma_points = np.median(err)\n",
    "\n",
    "    evidence_BIC = - Npoint * np.log(sigma_points) - 0.5 * Npoint * np.log(2 * np.pi) - 0.5 * BIC\n",
    "    evidence_AIC = - Npoint * np.log(sigma_points) - 0.5 * Npoint * np.log(2 * np.pi) - 0.5 * AIC\n",
    "\n",
    "    # Redefine all of the parameters given the MPFIT output\n",
    "    # Redefine array\n",
    "    res_sec = mpfit_result.params\n",
    "    # Recreate the dictionary\n",
    "    res_sec_dict = {key: val for key, val in zip(p0_names, res_sec)}\n",
    "\n",
    "    # pcerror = [rl_err, flux0_err, epoch_err, inclin_err, msmpr_err, ecc_err, omega_err, per_err, T0_err,\n",
    "    #           c1_err, c2_err, c3_err, c4_err, m_err, HSTP1_err, HSTP2_err, HSTP3_err, HSTP4_err, xshift1_err,\n",
    "    #           xshift2_err, xshift3_err, xshift4_err]\n",
    "    rl_err = pcerror[0]\n",
    "    epoch_err = pcerror[2]\n",
    "\n",
    "    # Recalculate a/R* (actually the constant for it) based on the new MsMpR value which may have been fit in the routine.\n",
    "    constant1 = (Gr * res_sec_dict['Per'] * res_sec_dict['Per'] / (4 * np.pi * np.pi)) ** (1 / 3.)\n",
    "    aval = constant1 * (res_sec_dict['MsMpR']) ** (1 / 3.)   # NOT-REUSED\n",
    "\n",
    "    print('\\nTRANSIT DEPTH rl in model {} of {} = {} +/- {}     centered at  {}'.format(s+1, nsys, res_sec_dict['rl'], rl_err, res_sec_dict['epoch']))\n",
    "\n",
    "    # OUTPUTS\n",
    "    # Re-Calculate each of the arrays dependent on the output parameters for the epoch\n",
    "    phase = (img_date - res_sec_dict['epoch']) / (res_sec_dict['Per'] / day_to_sec)\n",
    "    phase2 = np.floor(phase)\n",
    "    phase = phase - phase2\n",
    "    a = np.where(phase > 0.5)[0]\n",
    "    if len(a) > 0:\n",
    "        phase[a] = phase[a] - 1.0\n",
    "\n",
    "    HSTphase = (img_date - res_sec_dict['T0']) / HST_period\n",
    "    phase2 = np.floor(HSTphase)\n",
    "    HSTphase = HSTphase - phase2\n",
    "    k = np.where(HSTphase > 0.5)[0]\n",
    "    if len(k) > 0:\n",
    "        HSTphase[k] = HSTphase[k] - 1.0\n",
    "\n",
    "    # ...........................................\n",
    "    # TRANSIT MODEL fit to the data\n",
    "    # Calculate the impact parameter based on the eccentricity function\n",
    "    b0 = hstmarg.impact_param(res_sec_dict['Per'], res_sec_dict['MsMpR'], phase, res_sec_dict['inclin'])\n",
    "\n",
    "    mulimb01, mulimbf1 = hstmarg.occultnl(res_sec_dict['rl'], res_sec_dict['c1'], res_sec_dict['c2'], res_sec_dict['c3'], res_sec_dict['c4'], b0)\n",
    "\n",
    "    # ...........................................\n",
    "    # SMOOTH TRANSIT MODEL across all phase\n",
    "    # Calculate the impact parameter based on the eccentricity function\n",
    "    x2 = np.arange(4000) * 0.0001 - 0.2\n",
    "    b0 = hstmarg.impact_param(res_sec_dict['Per'], res_sec_dict['MsMpR'], x2, res_sec_dict['inclin'])\n",
    "\n",
    "    mulimb02, mulimbf2 = hstmarg.occultnl(res_sec_dict['rl'], res_sec_dict['c1'], res_sec_dict['c2'], res_sec_dict['c3'], res_sec_dict['c4'], b0)\n",
    "\n",
    "    systematic_model = hstmarg.sys_model(phase, HSTphase, sh, res_sec_dict['m_fac'], res_sec_dict['HSTP1'], res_sec_dict['HSTP2'],\n",
    "                                         res_sec_dict['HSTP3'], res_sec_dict['HSTP4'], res_sec_dict['xshift1'], res_sec_dict['xshift2'],\n",
    "                                         res_sec_dict['xshift3'], res_sec_dict['xshift4'])\n",
    "\n",
    "    fit_model = mulimb01 * res_sec_dict['flux0'] * systematic_model\n",
    "    residuals = (img_flux - fit_model) / res_sec_dict['flux0']\n",
    "    resid_scatter = np.std(w_residuals)\n",
    "    fit_data = img_flux / (res_sec_dict['flux0'] * systematic_model)\n",
    "    fit_err = np.copy(err)  # * (1.0 + resid_scatter)\n",
    "\n",
    "    if plotting:\n",
    "        plt.figure(2)\n",
    "        plt.clf()\n",
    "        plt.scatter(phase, img_flux, s=5)\n",
    "        plt.plot(x2, mulimb02, 'k')\n",
    "        plt.errorbar(phase, fit_data, yerr=err, fmt='m.')\n",
    "        plt.xlim(-0.03, 0.03)\n",
    "        plt.title('Model ' + str(s+1) + '/' + str(nsys))\n",
    "        plt.xlabel('Planet Phase')\n",
    "        plt.ylabel('Data')\n",
    "        plt.draw()\n",
    "        plt.pause(0.05)\n",
    "\n",
    "    # .............................\n",
    "    # Fill info into arrays to save to file once we iterated through all systems with both fittings.\n",
    "\n",
    "    sys_stats[s, :] = [AIC, BIC, DOF, CHI, resid_scatter]   # stats\n",
    "    sys_date[s, :] = img_date                               # input time data (x, date)\n",
    "    sys_phase[s, :] = phase                                 # phase\n",
    "    sys_rawflux[s, :] = img_flux                                   # raw lightcurve flux\n",
    "    sys_rawflux_err[s, :] = err\n",
    "    sys_flux[s, :] = fit_data                               # corrected lightcurve flux\n",
    "    sys_flux_err[s, :] = fit_err\n",
    "    sys_residuals[s, :] = residuals                         # residuals\n",
    "    sys_model[s, :] = mulimb02                              # smooth model\n",
    "    sys_model_phase[s, :] = x2                              # smooth phase\n",
    "    sys_systematic_model[s, :] = systematic_model           # systematic model\n",
    "    sys_params[s, :] = mpfit_result.params                  # parameters\n",
    "    sys_params_err[s, :] = pcerror                          # parameter errors\n",
    "    sys_depth[s] = res_sec_dict['rl']                            # depth\n",
    "    sys_depth_err[s] = rl_err                               # depth error\n",
    "    sys_epoch[s] = res_sec_dict['epoch']                         # transit time\n",
    "    sys_epoch_err[s] = epoch_err                            # transit time error\n",
    "    sys_evidenceAIC[s] = evidence_AIC                       # evidence AIC\n",
    "    sys_evidenceBIC[s] = evidence_BIC                       # evidence BIC\n",
    "\n",
    "    print('Another round done')\n",
    "\n",
    "# Save to file\n",
    "# For details on how to deal with this kind of file, see the notebook \"NumpyData.ipynb\"\n",
    "np.savez(os.path.join(outDir, 'analysis_circle_G141_'+run_name), sys_stats=sys_stats, sys_date=sys_date, sys_phase=sys_phase,\n",
    "         sys_rawflux=sys_rawflux, sys_rawflux_err=sys_rawflux_err, sys_flux=sys_flux, sys_flux_err=sys_flux_err,\n",
    "         sys_residuals=sys_residuals, sys_model=sys_model, sys_model_phase=sys_model_phase,\n",
    "         sys_systematic_model=sys_systematic_model, sys_params=sys_params, sys_params_err=sys_params_err,\n",
    "         sys_depth=sys_depth, sys_depth_err=sys_depth_err, sys_epoch=sys_epoch, sys_epoch_err=sys_epoch_err,\n",
    "         sys_evidenceAIC=sys_evidenceAIC, sys_evidenceBIC=sys_evidenceBIC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = mpfit_result.covar.flatten()[:nfree**2].reshape(nfree, nfree)\n",
    "ma = pd.DataFrame(test)\n",
    "print(ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri = np.sqrt(np.diag(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tri))\n",
    "print(tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.where(systematics == 0)[0]\n",
    "pcerror[ind] = tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcerror[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
