{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marginalisation\n",
    "\n",
    "In this notebook, we will load the data from after the second fit and perform the marginalisation.\n",
    "\n",
    "I need to get the data import working. The cells will have to be broken up more. I need to check for astropy units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import astropy.units as u\n",
    "from astropy.constants import G\n",
    "\n",
    "os.chdir('../HST_python')\n",
    "from config import CONFIG_INI\n",
    "import margmodule as marg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Load the results into the notebook and make sure the data looks right. We're loading the data after the second fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dpath = '/Users/ilaginja/Documents/data_from_repos/hst_marg_data/outputs/LevMar_2019-5-20'\n",
    "dpath = '/Users/hwakeford/Documents/GitHub/HST_Marginalization/outputs/'\n",
    "fname = 'LevMar_after_2nd_fit.npz'\n",
    "\n",
    "data = np.load(os.path.join(dpath, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate data\n",
    "print(data.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all data columns\n",
    "sys_stats = data['sys_stats']\n",
    "sys_date = data['sys_date']\n",
    "sys_phase = data['sys_phase']\n",
    "sys_rawflux = data['sys_rawflux']\n",
    "sys_rawflux_err = data['sys_rawflux_err']\n",
    "sys_flux = data['sys_flux']\n",
    "sys_flux_err = data['sys_flux_err']\n",
    "sys_residuals = data['sys_residuals']\n",
    "sys_model = data['sys_model']\n",
    "sys_model_phase = data['sys_model_phase']\n",
    "sys_systematic_model = data['sys_systematic_model']\n",
    "sys_params = data['sys_params']\n",
    "sys_depth = data['sys_depth']\n",
    "sys_depth_err = data['sys_depth_err']\n",
    "sys_epoch = data['sys_epoch']\n",
    "sys_epoch_err = data['sys_epoch_err']\n",
    "sys_evidenceAIC = data['sys_evidenceAIC']\n",
    "sys_evidenceBIC = data['sys_evidenceBIC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sys_stats.shape)\n",
    "print(sys_date.shape)\n",
    "print(sys_phase.shape)\n",
    "print(sys_rawflux.shape)\n",
    "# ... and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort by AIC evidence\n",
    "\n",
    "The AIC tells us how \"good\" the fit is.\n",
    "\n",
    "The evidence is the (simplified) negative log likelihood of the data begin fit by this model. Given this model, the data is likely to fit this model by *this* degree. How well can this model be described by the data we’ve given it.\n",
    "\n",
    "We don’t know the systematics very well, those change over time and what it looked at last. The Marginalisation is because if you slightly change your observation, we don’t know which of the 50 models actually describes observation best. We calculate for each model how well it describes data. Based on those numbers we get ordering from best to worst model - make a value that tells you which one fits the data best\n",
    "\n",
    "BIC penalizes models that are more complicated -  the more parameters you fit, the worse the model accordance with the data. Fewer free parameters are better.\n",
    "AIC only penalizes you by number of free parameters and not by how much data you have as well, it's a bit more lenient, it depends on how much you trust your data to decide whether to chose BIC and AIC. Literature usually prefers AIC, although BC is usually a slightly higher uncertainty. (We also AIC here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sys_evidenceAIC per model:')\n",
    "print(sys_evidenceAIC.shape)\n",
    "print(sys_evidenceAIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`a` is the sorted system evidence (AIC) array from largest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (np.sort(sys_evidenceAIC))[::-1]\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 systematic models\n",
    "\n",
    "Now we will have a closer look at the top 10 systematic models, sorted. by best AIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTOP 10 SYSTEMATIC MODELS: AIC')\n",
    "# Print the AIC for the top 10 systematic models\n",
    "print(a[:10])\n",
    "# Print all the AIC values (why?)\n",
    "print('All AIC:')\n",
    "print(sys_evidenceAIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat arrays - by ditching negative evidence values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFORMAT all arrays with just positive values\n",
    "pos = np.where(sys_evidenceAIC > -500)   #TODO: change hard coded number?\n",
    "if len(pos) == 0:\n",
    "    pos = -1\n",
    "    \n",
    "npos = len(pos[0])   # NOT-REUSED\n",
    "#TODO: What is getting printed here?\n",
    "print('npos: {}'.format(npos))\n",
    "print('POS positions = {}'.format(pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've gotten rid of models with AIC evidence we don't like (or something like that), we redefine the arrays. Although here, we still have ALL of the systematic models, because none of them seem to be falling out of line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_AIC = sys_evidenceAIC[pos]\n",
    "\n",
    "count_depth = sys_depth[pos]\n",
    "count_depth_err = sys_depth_err[pos]\n",
    "\n",
    "count_epoch = sys_epoch[pos]\n",
    "count_epoch_err = sys_epoch_err[pos]\n",
    "\n",
    "count_residuals = sys_residuals[pos]\n",
    "count_date = sys_date[pos]\n",
    "count_flux = sys_flux[pos]\n",
    "count_flux_err = sys_flux_err[pos]\n",
    "count_phase = sys_phase[pos]\n",
    "count_model_y = sys_model[pos]\n",
    "count_model_x = sys_model_phase[pos]\n",
    "\n",
    "print(count_AIC.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find most likely model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.min(count_AIC)\n",
    "w_q = (np.exp(count_AIC - beta)) / np.sum(np.exp(count_AIC - beta))\n",
    "\n",
    "print('beta: {}'.format(beta))\n",
    "print('w_q: {}'.format(w_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n01 = np.where(w_q >= 0.05)\n",
    "print('{} models have a weight over 0.05. -> Models: {} with weigths: {}'.format(n01[0].shape, n01, w_q[n01]))\n",
    "print('Most likely model is number {} at w_q={}'.format(np.argmax(w_q), np.max(w_q)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDNR is the scatter on the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sys_weight = np.argmax(w_q)   #TODO: redefined couple of lines below...\n",
    "print('SDNR best model from evidence = {}, for model {}'.format(\n",
    "      np.std(count_residuals[best_sys_weight,:]) / np.sqrt(2) * 1e6, best_sys_weight))\n",
    "\n",
    "rl_sdnr = np.zeros(len(w_q))\n",
    "for i in range(len(w_q)):\n",
    "    rl_sdnr[i] = (np.std(count_residuals[i,:]) / np.sqrt(2)) * 1e6\n",
    "best_sys_sdnr = np.argmin(rl_sdnr)\n",
    "\n",
    "print('SDNR best model from minimization = {} for model {}'.format(np.min(rl_sdnr), best_sys_sdnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "\n",
    "We can ignore these for now, we will deal with the plots later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(3)\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(w_q)\n",
    "plt.title('w_q')\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(rl_sdnr)\n",
    "plt.title('rl_sdnr')\n",
    "plt.subplot(3,1,3)\n",
    "plt.errorbar(np.arange(1, len(count_depth)+1), count_depth, yerr=count_depth_err, fmt='.')\n",
    "plt.title('count_depth')\n",
    "plt.draw()\n",
    "plt.pause(0.05)\n",
    "\n",
    "plt.figure(4)\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.scatter(sys_phase[0,:], sys_flux[0,:])\n",
    "plt.ylim(np.min(sys_flux[0,:]) - 0.001, np.max(sys_flux[0,:]) + 0.001)\n",
    "plt.xlabel('sys_phase')\n",
    "plt.ylabel('sys_flux')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.scatter(count_phase[best_sys,:], count_flux[best_sys,:])\n",
    "plt.plot(count_model_x[best_sys,:], count_model_y[best_sys,:])\n",
    "plt.ylim(np.min(count_flux[0,:]) - 0.001, np.max(count_flux[0,:]) + 0.001)\n",
    "plt.xlabel('count_phase')\n",
    "plt.ylabel('count_flux')\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.errorbar(count_phase[best_sys,:], count_residuals[best_sys,:], yerr=count_flux_err[best_sys,:], fmt='.')\n",
    "plt.ylim(-1000, 1000)\n",
    "plt.xlabel('count_phase')\n",
    "plt.ylabel('count_residuals')\n",
    "plt.hlines(0.0, xmin=np.min(count_phase[best_sys,:]), xmax=np.max(count_phase[best_sys,:]), colors='r', linestyles='dashed')\n",
    "#plt.hlines(0.0 - (rl_sdnr[best_sys] * cut_down), xmin=np.min(count_phase[best_sys,:]), xmax=np.max(count_phase[best_sys,:]), colors='r', linestyles='dotted')\n",
    "#plt.hlines(0.0 + (rl_sdnr[best_sys] * cut_down), xmin=np.min(count_phase[best_sys,:]), xmax=np.max(count_phase[best_sys,:]), colors='r', linestyles='dotted')\n",
    "plt.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform the marginalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Radius ratio - this one always gets calculated\n",
    "marg_rl, marg_rl_err = marg.marginalisation(count_depth, count_depth_err, w_q)\n",
    "print('Rp/R* = {} +/- {}'.format(marg_rl, marg_rl_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Center of transit time (epoch)\n",
    "marg_epoch = None\n",
    "marg_epoch_err = None\n",
    "if not tmodel.epoch.frozen:\n",
    "    marg_epoch, marg_epoch_err = marg.marginalisation(count_epoch, count_epoch_err, w_q)\n",
    "    print('Epoch = {} +/- {}'.format(marg_epoch, marg_epoch_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inclination\n",
    "marg_inclin_rad = None\n",
    "marg_inclin_rad_err = None\n",
    "marg_inclin_deg = None\n",
    "marg_inclin_deg_err = None\n",
    "\n",
    "if not tmodel.inclin.frozen:\n",
    "    # Inclication in radians\n",
    "    marg_inclin_rad, marg_inclin_rad_err = marg.marginalisation(sys_params[:, 3], sys_params_err[:, 3], w_q)\n",
    "    print('inc (rads) = {} +/- {}'.format(marg_inclin_rad, marg_inclin_rad_err))\n",
    "\n",
    "    # Inclination in degrees\n",
    "    conv1 = sys_params[:, 3] / (2 * np.pi / 360)\n",
    "    conv2 = sys_params_err[:, 3] / (2 * np.pi / 360)\n",
    "    marg_inclin_deg, marg_inclin_deg_err = marg.marginalisation(conv1, conv2, w_q)\n",
    "    print('inc (deg) = {} +/- {}'.format(marg_inclin_deg, marg_inclin_deg_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MsMpR\n",
    "marg_msmpr = None\n",
    "marg_msmpr_err = None\n",
    "marg_aors = None\n",
    "marg_aors_err = None\n",
    "\n",
    "if not tmodel.msmpr.frozen:\n",
    "    marg_msmpr, marg_msmpr_err = marg.marginalisation(sys_params[:, 4], sys_params_err[:, 4], w_q)\n",
    "    print('MsMpR = {} +/- {}'.format(marg_msmpr, marg_msmpr_err))\n",
    "\n",
    "    # Recalculate a/R* (actually the constant for it) based on the new MsMpR value which may have been fit in the routine.\n",
    "    constant1 = (G * np.square((tmodel.period.val * u.d).to(u.s)) / (4 * np.pi * np.pi)) ** (1 / 3.)   #TODO: period is constant - make pretty\n",
    "\n",
    "    marg_aors = constant1 * (marg_msmpr ** (1./3.))\n",
    "    marg_aors_err = constant1 * (marg_msmpr_err ** (1./3.)) / marg_aors\n",
    "    print('a/R* = {} +/- {}'.format(marg_aors, marg_aors_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to file\n",
    "\n",
    "E.g. for comparison to IDL results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez(os.path.join(outDir, 'analysis_circle_G141_marginalised_'+run_name), w_q=w_q, best_sys=best_sys,\n",
    "#          marg_rl=marg_rl, marg_rl_err=marg_rl_err, marg_epoch=marg_epoch, marg_epoch_err=marg_epoch_err,\n",
    "#          marg_inclin_rad=marg_inclin_rad, marg_inclin_rad_err=marg_inclin_rad_err, marg_inclin_deg=marg_inclin_deg,\n",
    "#          marg_inclin_deg_err=marg_inclin_deg_err, marg_msmpr=marg_msmpr, marg_msmpr_err=marg_msmpr_err,\n",
    "#          marg_aors=marg_aors, marg_aors_err=marg_aors_err, rl_sdnr=rl_sdnr, pos=pos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
